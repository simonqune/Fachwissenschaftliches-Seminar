\chapter{Datengrundlage und Vorverarbeitung}

\section{3D-Datenformate und Datentypen}
Bei der semantischen Segmentierung von 3D-Daten spielen die zugrunde liegenden
3D-Datenformate eine elementare Rolle. Diese bilden die Grundlage für die
Erfassung, Speicherung und Verarbeitung von 3D-Daten, die für die semantische
Segmentierung verwendet werden. In diesem Kapitel werden die beiden
verbreitetsten 3D-Datenformate und Datentypen untersucht, die in der Forschung
und Praxis eingesetz werden.

Ein wichtiges 3D-Datenformat ist das Punktewolkenformat, das häufig von
LiDAR-Sensoren erzeugt wird. Punktewolken sind Sammlungen von 3D-Punkten, die
die Oberfläche von Objekten in der Umgebung darstellen. Sie können in
verschiedenen Dateiformaten gespeichert werden, wie beispielsweise dem
ASCII-Format oder dem binären LAS-Format (LASer File Format), das speziell für
LiDAR-Daten entwickelt wurde. Diese Formate ermöglichen die Speicherung von
großen Mengen an Punkten mit 3D-Koordinaten, Intensitätsinformationen und
weiteren Attributen, die zur semantischen Segmentierung verwendet werden
können. Im Vergleich zu Bildern weißen Punktwolken eine stark variable
Punktdichte auf. Dies lässt sich durch Faktoren, wie eine ungleichmäßige
Abtastung des Raumes, der Verdeckung von Objekten und der relativen Ausrichtung
des Objektes zum Sensor begründen \cite{8578570}. Das Punktwolkenformat erzeugt
dabei große Datenmengen, was zu einer rechenintensiven Verarbeitung der Daten
führen kann.

Neben Punktewolken werden auch 3D-Gitter oder Voxel-Daten oft für die
semantische Segmentierung verwendet. Voxel sind volumetrische Elemente, die den
Raum in einem dreidimensionalen Gitter unterteilen. Jedes Voxel enthält dabei
Informationen über Materialeigenschaften, Farbe oder Textur des Objektes an
diesem Punkt. Voxel-Daten können in verschiedenen Formaten gespeichert werden,
wie zum Beispiel das binäre OctoMap-Format oder dem ASCII-Format. Sie bieten
dabei eine effektive Möglichkeit, komplexe dreidimensionale Strukturen
darzustellen und weiter zu analysieren. Die Voxeldichte im Raum kann dabei frei
gewählt werden und bestimmt so die Auflösung und den Speicherbedarf des
Datensatzes.

\section{Vorverarbeitungsschritte wie Filterung, Normalenberechnung und Downsampling}

Die Vorverarbeitung von 3D-Daten ist ein wichtiger Schritt in der semantischen
Segmentierung, um die Qualität und Genauigkeit der Segmentierungsergebnisse zu
verbessern. In diesem Kapitel werden verschiedene Vorverarbeitungsschritte wie
Filterung, Normalenberechnung und Downsampling betrachtet, die oft in der
Praxis angewendet werden.

Filterung von 3D-Daten: Die Filterung von 3D-Daten beinhaltet das Entfernen von
unerwünschtem Rauschen oder Ausreißern, um die Qualität der Daten zu
verbessern. Dies kann durch verschiedene Filtertechniken erfolgen, wie zum
Beispiel Medianfilter, Gaußscher Filter \cite{9191237} oder region growing und
Bilateralfilter \cite{6460813}. Diese Filter können angewendet werden, um
Rauschen oder Ausreißer in den 3D-Punktwolken oder Voxel-Daten zu reduzieren
und somit die Qualität der Daten für die semantische Segmentierung zu
verbessern.

Normalenberechnung: Die Berechnung von Normalen ist ein wichtiger Schritt, um
die geometrische Information der 3D-Daten zu erfassen. Normalen sind Vektoren,
die senkrecht zur Oberfläche von Objekten in der Umgebung stehen und die
Orientierung der Oberfläche angeben. Die Normalenberechnung kann auf Basis von
Punktwolken durchgeführt werden und ermöglicht es, die Richtung und
Orientierung der Objektoberflächen zu erfassen, was für die semantische
Segmentierung von Objekten von Bedeutung ist.

Downsampling: Das Downsampling von 3D-Daten beinhaltet die Reduzierung der
Datenmenge, um die Verarbeitungsgeschwindigkeit und den Speicherbedarf zu
reduzieren. Dies kann durch verschiedene Techniken erfolgen. Häufig erfolgt
dies in Form von Voxel-Grid-Downsampling. Dabei wird der Raum, in der sich die
Punktwolke befindet, in gleichmäßige Voxel unterteilt, wobei für jedes Voxel
der Schwerpunkt der darin enthaltenen Punkte berechnet wird. Danach wird eine
bestimmte Anzahl an Punkten, häufig durch ihre nähe zum Schwerpunkt, ausgewählt
und in das Voxel-Grid übernommen. Ziel des Downsamplings ist es, die Datenmenge
zu reduzieren, während wichtige strukturelle und semantische Informationen
erhalten bleiben.

\section{Datenannotation und Ground Truth-Erstellung}

Die Datenannotation und die Erstellung von Ground Truth sind entscheidende
Schritte bei der semantischen Segmentierung von 3D-Daten. Sie liefern die
Trainingsdaten für maschinelles Lernen und ermöglichen das Training und die
Evaluation von Segmentierungsmodellen. Bei der Datenannotation werden
semantische Labels oder Klasseninformationen manuell oder automatisch den
3D-Daten zugeordnet. Dies ist wichtig, um die Daten bestimmten Klassen oder
Kategorien zuzuweisen. Die Qualität und Genauigkeit der Datenannotation sind
entscheidend für die Leistungsfähigkeit von semantischen
Segmentierungsalgorithmen. Die Erstellung von Ground Truth umfasst die
Erstellung von referenzbasierten Segmentierungsergebnissen, die als Grundlage
für das Training und die Evaluation von Segmentierungsmodellen dienen. Die
Ground Truth kann manuell oder automatisch erstellt werden, um die
Zuverlässigkeit und Vergleichbarkeit von Segmentierungsergebnissen
sicherzustellen und die Qualität von trainierten Modellen zu überprüfen.