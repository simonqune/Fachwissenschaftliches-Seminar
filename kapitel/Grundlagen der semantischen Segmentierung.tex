\chapter{Grundlagen der semantischen Segmentierung}

\section{Verfahren zur semantischen Segmentierung}

Ziel der Semantischen Segmentierung von 3D-Daten ist es, jedem Punkt im Raum
einer bestimmten Kategorie zuzuordnen und dadurch Bereiche des Bildes in
klassifizierte Objekte zu unterteilen. Hierfür gibt es verschiedene Ansätze,
die auf erweiterten neuronalen Netzen basieren.

\subsection{Convolutional Neural Networks (CNNs)}
Convolutional Neural Networks (CNNs) sind eine Art von künstlichen neuronalen
Netzen, die speziell für die Verarbeitung von Bildern entwickelt wurden. Sie
bestehen aus mehreren Schichten, darunter Convolutional Layers, Pooling Layers
und Fully Connected Layers, die miteinander verbunden sind. Die Architektur der
CNNs ist dabei nicht vorgegeben, folgt aber in der Praxis immer einer ähnlichen
Vorlage. Ein Input-Layer beinhaltet die Pixelwerte des Bildes. Darauf folgen in
der Regel ein oder zwei Convolutional-Layers, woraufhin sich ein Pooling-Layer
anreiht. Die Kombination aus Convolutional- und Pooling-Layer kann dabei je
nach Komplexität beliebig oft im Netz vorkommen. Am Ende folgt ein
Fully-Connected-Layer an den der Output anknüpft.[GRAFIK?] Die Convolutional
Layers können vereinfacht als Filter-Layer betrachtet werden und extrahieren
Merkmale aus den Eingabebildern. Dabei wird jeder Bereich des Bildes mit
Kernels (Filtern) gefalten und erzeugen eine 2D-Aktivierungskarte. Die kernels
besitzen dabei häufig kleine räumliche Dimensionalitäten, erstrecken sich aber
über die Gesamte Tiefe des Eingangsbildes. Pooling Layers dienen dazu, die
Dimensionen der Ausgabe des Convolutional-Layers zu reduzieren und somit die
Rechnenkomplexität des Modells zu verringern. Die Fully Connected Layers am
Ende des Netzes verarbeiten schließlich die extrahierten Aktivierungen und
versuchen daraus Klassifizierungsergebnisse zu gewinnen. Der
Hauptanwendungsbereich von CNNs liegt dabei in der Klassifikation von Bildern
in vorbestimmte Kategorien. \cite{OShea.11262015}.

\subsection{Fully Convolutional Networks (FCNs)}
Fully Convolutional Networks (FCNs) sind eine Weiterentwicklung von
Convolutional Neural Networks (CNNs), die speziell für die Aufgabe der
semantischen Segmentierung von Bildern entwickelt wurden. Im Gegensatz zu
herkömmlichen CNNs, die für die Klassifizierung von Bildern ausgelegt sind,
können FCNs die Pixel jedes Eingabebildes direkt klassifizieren und damit die
räumliche Information beibehalten. FCNs verwenden dabei ausschließlich
Convolutional-Layers und Pooling-Layers, nicht aber Fully-Connected-Layers.
Dies ermöglicht es eine Merkmalskarte des Eingabebildes zu erzeugen, auf der
jedes Pixel einer bestimmten Klasse zugeordnet wird. Durch die Verwendung von
FCNs können somit komplizierte Zusammenhänge innerhalb von Bildern auf der
Ebene der Pixel identifiziert werden, was für Anwendungen wie die autonome
Navigation oder Objekterkennung von großer Bedeutung ist. \cite{7298965}

\subsection{Region-based Convolutional Neural Networks (R-CNNs)}
Region-based Convolutional Neural Networks (R-CNNs) sind eine Weiterentwicklung
von Convolutional Neural Networks, die speziell für die Aufgabe der
Objekterkennung in Bildern entwickelt wurden. Im Gegensatz zu herkömmlichen
CNNs, die eine feste Größe der Eingabebilder erfordern, verwenden R-CNNs eine
Region Proposal Technik, um Regions of Interest (ROI) innerhalb des Bildes zu
detektieren. Anschließend wird auf die ausgewählten Bereiche ein FCN
angewendet, um diesen auf Pixelebene zu klassifizieren. R-CNNs erzielen dadurch
eine höhere Genauigkeit als herkömmliche CNNs bei der Erkennung von Objekten in
Bildern und werden daher häufig in der Robotik und im autonomen Fahren
eingesetzt. \cite{8237584}

\subsection{Encoder-Decoder-Architekturen:}
Encoder-Decoder-Architekturen sind eine spezielle Art von neuronalen Netzen,
die zur semantischen Segmentierung von Bildern eingesetzt werden. Der Name
leitet sich von der Architektur ab, die aus zwei Hauptkomponenten besteht: dem
Encoder und dem Decoder. Der Encoder besteht aus mehreren Faltungsschichten,
die das Eingabebild schrittweise in eine kompakte, abstrakte Repräsentation
komprimieren, die die Merkmale des Bildes enthält. Der Decoder besteht aus
mehreren Deconvolution-Schichten, die diese kompakte Repräsentation
schrittweise wieder in eine vollständige Bildgröße erweitern und dabei die
semantische Information des Bildes beibehalten. Encoder-Decoder-Architekturen
sind sehr effektiv bei der Segmentierung von Bildern und haben in den letzten
Jahren aufgrund ihrer hohen Genauigkeit und Effizienz in der Bildanalyse und
-verarbeitung an Bedeutung gewonnen.
\section{Datenannotation und Ground Truth-Erstellung}

Datenannotation und Ground Truth-Erstellung sind wichtige Schritte bei der
semantischen Segmentierung von 3D-Daten, da sie die Trainingsdaten für
maschinelles Lernen bereitstellen und Modelle für die Segmentierung von
3D-Daten trainieren und evaluieren. Bei der Datenannotation werden semantische
Labels oder Klasseninformationen manuell oder automatisch zu den 3D-Daten
hinzugefügt, um sie bestimmten Klassen oder Kategorien zuzuordnen. Die Qualität
und Genauigkeit der Datenannotation sind entscheidend für die
Leistungsfähigkeit von semantischen Segmentierungsalgorithmen. Die Ground
Truth-Erstellung beinhaltet die Erstellung von referenzbasierten
Segmentierungsergebnissen, die als Grundlage für das Training und die
Evaluierung von semantischen Segmentierungsalgorithmen dienen. Die Ground Truth
kann manuell oder automatisch erstellt werden, um die Zuverlässigkeit und
Vergleichbarkeit von Segmentierungsergebnissen zu gewährleisten und die
Qualität von trainierten Modellen zu überprüfen.

\section{Evaluierung von Verfahren zur semantischen Segmentierung}
Die Evaluierung von Verfahren zur semantischen Segmentierung erfolgt in der
Regel anhand von Metriken wie der "Intersection over Union" (IoU), auch
"Jaccard Index" genannt. Dieser Wert gibt an, wie viel Prozent der
vorhergesagten Pixel tatsächlich richtig klassifiziert wurden im Verhältnis zu
den tatsächlich vorhandenen Pixeln. Weitere Metriken sind die
"Pixelgenauigkeit" (Pixel Accuracy), die "Klassen-Genauigkeit" (Class Accuracy)
und die "Mittlere-Klassen-Genauigkeit" (Mean Class Accuracy). Für die
Evaluierung wird in der Regel ein Testdatensatz verwendet, der sowohl Bilder
als auch Ground-Truth-Masken enthält. Anhand dieser Daten wird das Verfahren
trainiert und anschließend auf dem Testdatensatz ausgewertet. Die Bewertung der
Ergebnisse ermöglicht die Beurteilung der Leistung des Verfahrens und die
Vergleichbarkeit mit anderen Ansätzen.
