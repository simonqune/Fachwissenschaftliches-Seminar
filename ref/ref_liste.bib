@inproceedings{9102769,
  author    = {Yang, Kaihong and Bi, Sheng and Dong, Min},
  booktitle = {2020 IEEE International Conference on Multimedia and Expo (ICME)},
  title     = {Lightningnet: Fast and Accurate Semantic Segmentation for Autonomous Driving Based on 3D LIDAR Point Cloud},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1-6},
  doi       = {10.1109/ICME46284.2020.9102769}
}
  @inproceedings{8100085,
  author    = {Ge, Liuhao and Liang, Hui and Yuan, Junsong and Thalmann, Daniel},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {3D Convolutional Neural Networks for Efficient and Robust Hand Pose Estimation from Single Depth Images},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {5679-5688},
  doi       = {10.1109/CVPR.2017.602}
}
  @inproceedings{9423307,
  author    = {Pham, Tuan},
  booktitle = {2020 Applying New Technology in Green Buildings (ATiGB)},
  title     = {Semantic Road Segmentation using Deep Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {45-48},
  doi       = {10.1109/ATiGB50996.2021.9423307}
}
  @inproceedings{9420573,
  author    = {Hosein Hamian, Mohammad and Beikmohammadi, Ali and Ahmadi, Ali and Nasersharif, Babak},
  booktitle = {2021 26th International Computer Conference, Computer Society of Iran (CSICC)},
  title     = {Semantic Segmentation of Autonomous Driving Images by the Combination of Deep Learning and Classical Segmentation},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1-6},
  doi       = {10.1109/CSICC52343.2021.9420573}
}
  @inproceedings{8529992,
  author    = {Liu, Jingyun and Sun, Qiao and Fan, Zhe and Jia, Yudong},
  booktitle = {2018 IEEE 3rd Optoelectronics Global Conference (OGC)},
  title     = {TOF Lidar Development in Autonomous Vehicle},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {185-190},
  doi       = {10.1109/OGC.2018.8529992}
}
  @inproceedings{8932817,
  author    = {DANDIL, Emre and ÇEVİK, Kerim Kürşat},
  booktitle = {2019 3rd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)},
  title     = {Computer Vision Based Distance Measurement System using Stereo Camera View},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {1-4},
  doi       = {10.1109/ISMSIT.2019.8932817}
}
  @inproceedings{7025195,
  author    = {Dalbah, Yosef and Rohr, Stephan and Wahl, Friedrich M.},
  booktitle = {2014 IEEE International Conference on Image Processing (ICIP)},
  title     = {Detection of dynamic objects for environment mapping by time-of-flight cameras},
  year      = {2014},
  volume    = {},
  number    = {},
  pages     = {971-975},
  doi       = {10.1109/ICIP.2014.7025195}
}
  @inproceedings{7992709,
  author    = {Anwar, Inzamam and Lee, Sukhan},
  booktitle = {2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)},
  title     = {High performance stand-alone structured light 3D camera for smart manipulators},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {192-195},
  doi       = {10.1109/URAI.2017.7992709}
}
  @inproceedings{9262651,
  author    = {da Silva Neto, José Gomes and da Lima Silva, Pedro Jorge and Figueredo, Filipe and Teixeira, João Marcelo Xavier Natário and Teichrieb, Veronica},
  booktitle = {2020 22nd Symposium on Virtual and Augmented Reality (SVR)},
  title     = {Comparison of RGB-D sensors for 3D reconstruction},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {252-261},
  doi       = {10.1109/SVR51698.2020.00046}
}
  @inproceedings{8578570,
  author    = {Zhou, Yin and Tuzel, Oncel},
  booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title     = {VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {4490-4499},
  doi       = {10.1109/CVPR.2018.00472}
}
  @inproceedings{9191237,
  author    = {Thurnhofer-Hemsi, Karl and López-Rubio, Ezequiel and Roé-Vellvé, Núria and Deka, Lipika},
  booktitle = {2020 IEEE International Conference on Image Processing (ICIP)},
  title     = {Super-Resolution of 3D MRI Corrupted by Heavy Noise With the Median Filter Transform},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {3015-3019},
  doi       = {10.1109/ICIP40778.2020.9191237}
}
  @inproceedings{6460813,
  author    = {Chen, Li and Lin, Hui and Li, Shutao},
  booktitle = {Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},
  title     = {Depth image enhancement for Kinect using region growing and bilateral filter},
  year      = {2012},
  volume    = {},
  number    = {},
  pages     = {3070-3073},
  doi       = {}
}
  @misc{11262015,
  abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs.  This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.},
  author   = {O'Shea, Keiron and Nash, Ryan},
  date     = {11/26/2015},
  title    = {An Introduction to Convolutional Neural Networks},
  url      = {https://arxiv.org/pdf/1511.08458.pdf},
  urldate  = {5/8/2023},
  file     = {acf529c2-9ceb-4247-af2b-3d18386a3378:C\:\\Users\\kuhns\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\ffp672gkolya7su4r7atzhmr8k0hhpf6fnt87hoagh3kec\\Citavi Attachments\\acf529c2-9ceb-4247-af2b-3d18386a3378.pdf:pdf;8d823a62-a4e7-4d43-bed5-6ba57d4d8b17:C\:\\Users\\kuhns\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\ffp672gkolya7su4r7atzhmr8k0hhpf6fnt87hoagh3kec\\Remote Attachments\\8d823a62-a4e7-4d43-bed5-6ba57d4d8b17.pdf:pdf}
}
@inproceedings{7298965,
  author    = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Fully convolutional networks for semantic segmentation},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {3431-3440},
  doi       = {10.1109/CVPR.2015.7298965}
}
  @inproceedings{8237584,
  author    = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
  booktitle = {2017 IEEE International Conference on Computer Vision (ICCV)},
  title     = {Mask R-CNN},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {2980-2988},
  doi       = {10.1109/ICCV.2017.322}
}
  @article{7803544,
  author  = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
  year    = {2017},
  volume  = {39},
  number  = {12},
  pages   = {2481-2495},
  doi     = {10.1109/TPAMI.2016.2644615}
}

@article{987567547,
  abstract = {To investigate forest resources, it is necessary to identify the tree species. However, it is a challenge to identify tree species using 3D point clouds of trees collected by light detection and ranging (LiDAR). PointNet++, a point cloud deep learning network, can effectively classify 3D objects. It is important to establish high-quality individual tree point cloud datasets when applying PointNet++ to identifying tree species. However, there are different data processing methods to produce sample datasets, and the processes are tedious. In this study, we suggest how to select the appropriate method by designing comparative experiments. We used the backpack laser scanning (BLS) system to collect point cloud data for a total of eight tree species in three regions. We explored the effect of tree height on the classification accuracy of tree species by using different point cloud normalization methods and analyzed the effect of leaf point clouds on classification accuracy by separating the leaves and wood of individual tree point clouds. Five downsampling methods were used: farthest point sampling (FPS), K-means, random, grid average sampling, and nonuniform grid sampling (NGS). Data with different sampling points were designed for the experiments. The results show that the tree height feature is unimportant when using point cloud deep learning methods for tree species classification. For data collected in a single season, the leaf point cloud has little effect on the classification accuracy. The two suitable point cloud downsampling methods we screened were FPS and NGS, and the deep learning network could provide the most accurate tree species classification when the number of individual tree point clouds was in the range of 2048--5120. Our study further illustrates that point-based end-to-end deep learning methods can be used to classify tree species and identify individual tree point clouds. Combined with the low-cost and high-efficiency BLS system, it can effectively improve the efficiency of forest resource surveys.},
  author   = {Liu, Bingjie and Chen, Shuxin and Huang, Huaguo and Tian, Xin},
  year     = {2022},
  title    = {Tree Species Classification of Backpack Laser Scanning Data Using the PointNet++ Point Cloud Deep Learning Method},
  url      = {https://www.mdpi.com/2072-4292/14/15/3809},
  pages    = {3809},
  volume   = {14},
  number   = {15},
  issn     = {2072-4292},
  journal  = {Remote Sensing},
  doi      = {10.3390/rs14153809},
  file     = {b86129cd-519d-4bf1-a016-1ed17021db07:C\:\\Users\\kuhns\\AppData\\Local\\Swiss Academic Software\\Citavi 6\\ProjectCache\\ffp672gkolya7su4r7atzhmr8k0hhpf6fnt87hoagh3kec\\Citavi Attachments\\b86129cd-519d-4bf1-a016-1ed17021db07.pdf:pdf}
}
@article{CGV-079,
  url     = {http://dx.doi.org/10.1561/0600000079},
  year    = {2020},
  volume  = {12},
  journal = {Foundations and Trends® in Computer Graphics and Vision},
  title   = {Computer Vision for Autonomous Vehicles: Problems, Datasets and State of the Art},
  doi     = {10.1561/0600000079},
  issn    = {1572-2740},
  number  = {1–3},
  pages   = {1-308},
  author  = {Joel Janai and Fatma Güney and Aseem Behl and Andreas Geiger}
}
@inproceedings{8206396,
  author    = {Ha, Qishen and Watanabe, Kohei and Karasawa, Takumi and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {MFNet: Towards real-time semantic segmentation for autonomous vehicles with multi-spectral scenes},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {5108-5115},
  doi       = {10.1109/IROS.2017.8206396}
}
<@article{20222324,
  title     = {Multimodal Semantic Segmentation in Autonomous Driving: A Review of Current Approaches and Future Perspectives},
  volume    = {10},
  issn      = {2227-7080},
  url       = {http://dx.doi.org/10.3390/technologies10040090},
  doi       = {10.3390/technologies10040090},
  number    = {4},
  journal   = {Technologies},
  publisher = {MDPI AG},
  author    = {Rizzoli, Giulia and Barbato, Francesco and Zanuttigh, Pietro},
  year      = {2022},
  month     = {Jul},
  pages     = {90}
}
  @inproceedings{7035807,
  author    = {Kerl, Christian and Souiai, Mohamed and Sturm, Jürgen and Cremers, Daniel},
  booktitle = {2014 2nd International Conference on 3D Vision},
  title     = {Towards Illumination-Invariant 3D Reconstruction Using ToF RGB-D Cameras},
  year      = {2014},
  volume    = {1},
  number    = {},
  pages     = {39-46},
  doi       = {10.1109/3DV.2014.62}
}
  @article{elphcik1991using,
  title   = {Using the LAS format-part I.[Well log files]},
  author  = {Elphcik, RY},
  journal = {Geobyte;(United States)},
  volume  = {6},
  number  = {6},
  year    = {1991}
}
@inproceedings{6706719,
  author    = {Orts-Escolano, Sergio and Morell, Vicente and García-Rodríguez, José and Cazorla, Miguel},
  booktitle = {The 2013 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Point cloud data filtering and downsampling using growing neural gas},
  year      = {2013},
  volume    = {},
  number    = {},
  pages     = {1-8},
  doi       = {10.1109/IJCNN.2013.6706719}
}
  @article{niessner2013real,
  title     = {Real-time 3D reconstruction at scale using voxel hashing},
  author    = {Nie{\ss}ner, Matthias and Zollh{\"o}fer, Michael and Izadi, Shahram and Stamminger, Marc},
  journal   = {ACM Transactions on Graphics (ToG)},
  volume    = {32},
  number    = {6},
  pages     = {1--11},
  year      = {2013},
  publisher = {ACM New York, NY, USA}
}
@article{HAN2017103,
  title    = {A review of algorithms for filtering the 3D point cloud},
  journal  = {Signal Processing: Image Communication},
  volume   = {57},
  pages    = {103-112},
  year     = {2017},
  issn     = {0923-5965},
  doi      = {https://doi.org/10.1016/j.image.2017.05.009},
  url      = {https://www.sciencedirect.com/science/article/pii/S0923596517300930},
  author   = {Xian-Feng Han and Jesse S. Jin and Ming-Jie Wang and Wei Jiang and Lei Gao and Liping Xiao},
  keywords = {3D point cloud, Filtering methods, Feature-preserving, Noise reduction},
  abstract = {In recent years, 3D point cloud has gained increasing attention as a new representation for objects. However, the raw point cloud is often noisy and contains outliers. Therefore, it is crucial to remove the noise and outliers from the point cloud while preserving the features, in particular, its fine details. This paper makes an attempt to present a comprehensive analysis of the state-of-the-art methods for filtering point cloud. The existing methods are categorized into seven classes, which concentrate on their common and obvious traits. An experimental evaluation is also performed to demonstrate robustness, effectiveness and computational efficiency of several methods used widely in practice.}
}
@article{8309343,
  author  = {Zhang, Zhengxin and Liu, Qingjie and Wang, Yunhong},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  title   = {Road Extraction by Deep Residual U-Net},
  year    = {2018},
  volume  = {15},
  number  = {5},
  pages   = {749-753},
  doi     = {10.1109/LGRS.2018.2802944}
}
@inproceedings{Girshick_2015_ICCV,
  author    = {Girshick, Ross},
  title     = {Fast R-CNN},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month     = {December},
  year      = {2015}
}











